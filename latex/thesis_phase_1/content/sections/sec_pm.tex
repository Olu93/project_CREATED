\documentclass[./../../paper.tex]{subfiles}
\graphicspath{{\subfix{./../../figures/}}}

\begin{document}
\subsection{A definition for Business Processes}
Before elaborating on Process Mining, we have to establsih the meaning of the term \emph{process} in the context of this paper. The term is broadly used in many contexts and therefore has a rich semantic volume. A process generally refers to something that advances and changes over time\autocite{_DefinitionPROCESS_}.
Although, legal or biological processes may be valid understandings, we focus on processes \emph{business processes}.

An example is a loan application process in which an applicant may request a loan at a specific point in time. The case is then assessed and reviewed by multiple approvers and ends in a final decision. The loan may be granted or denied. The \emph{business} part may be misleading as these processes are not confined to commercial settings. For instance, a medical business process may cover a patients admission to a hospital, followed by a series of diagnostics and treatments and ending with the recovery or death of a patient. Another example from a human-computer-interaction\attention{Add to glossary} perspective would be an order process for an online retail service like Amazon. The buyer might start the process by adding articles to the shopping cart and proceeding with specifying their bank account details. This order process would end with the submission or receival of the order.

All of these examples have a number of common characteristics. They have a clear starting point which is followed by numerous intermediary steps and end in one of the possible sets of outcomes.For this paper we will refer to each step, including start and end points, as \gls{event}. Each \gls{event} may contain additional information in the form of event attributes. A collection of these \glspl{event} refer to a \gls{instance}, if they all relate to a single run of a process. In line with the aforementioned examples, these \glspl{instance} could be understood as a single loan application, a medical case or a buy order. We can also attach \gls{instance} related information to each instance. Examples would be the applicants race, a patients age or the buyers budget. In its entirety, a business process can be summarised as a \emph{graph} or \emph{flowchart}, in which every node represents an event and each arc the path to another event. This graphical representation is referred to as \emph{process map}. \autoref{fig:example_process} shows an example of such a representation.


\begin{figure}[htb]
    \centering
    \includegraphics[width=0.25\textwidth]{figures/misc/placeholder.png}
    \caption{This graph shows an example of various process maps.}
    \label{fig:example_process}
\end{figure}



\noindent In conclusion, in this thesis a \emph{business process} refers to \begin{quote}
    \emph{A finite series of discrete events with one or more starting points, intermediary steps and end points.}
\end{quote}
However, we have to address a number of issues with this definition.
First, this definition excludes infinite processes like \attention{XXX} or continuous processes such as \attention{XXX}. There may be valid arguments to include processes with these characteristics, but they are not relevant for this thesis.
Second, in each example we deliberately used words that accentuate modality such as \emph{may}, \emph{can} or \emph{would}. It is important to understand that each process anchors its definition in its application context. Hence, what defines a business process is indisputably subjective. For instance, while an online marketplace like Amazon might be interested in the process from the customers first click to the successful shipment, an Amazon vendor might be interested in the delivery process of a product only.
Third, the example provided in \autoref{fig:example_process} may not relate to the reality of a data generating process. In line with the second point, these examples subjective models of a process. They may or may not be accurate. The \emph{true} process is often unknown to every actor. Therefore, we will distinguish between the \emph{true process model} and a \emph{process model}. The \emph{true process model} is a hypothetical concept whose \emph{true} structure remains unknown.

\subsection{What is Process Mining}
Having established our understanding of a process, we can turn towards \emph{Process Mining}. This young discipline has many connections to other fields that focus on the modeling and analysis of processes such as \gls{CPI} or \gls{BPM}. However, its data-centric approaches originate in \gls{dm}.
The authors \citeauthor{vanderaalst_ProcessMiningManifesto_2012} describe this field as a discipline \enquote{to discover, monitor and improve real processes (i.e., not assumed processes) by extracting knowledge from event logs readily available in today's (information) systems}\autocite{vanderaalst_ProcessMiningManifesto_2012}. The discipline revolves around the analysis of \glspl{log}.
% TODO: Minor mistake with information systems
An \gls{log} is a collection of \glspl{instance}. These logs are retrievable from various sources like an \glspl{IS} or database. Those logs are often stored in data formats such as \gls{CSV} or \gls{XES}.

\subsection{The Challenges of Process Mining}
As mentioned in \autoref{sec:intro}, process data modelling and analysis is a challenging task. \citeauthor{vanderaalst_ProcessMiningManifesto_2012} mentions a number of issues that arise from processes\autocite{vanderaalst_ProcessMiningManifesto_2012}.

The first issue arises from the quality of the data set. Process logs are seldomly collected with the primary goal of mining information and hence, often appear to be of subpar quality. The information is often in complete due to a lack of context information, the ommision of logged process steps or wrong levels of granularity.

This issue is exacerbated by the second major issue with process data. Mainly, its complexity. Not only does a process logs complexity arise from the variety of data sources and differing levels of complexity, but also from the datas' characteristics. The data can often be viewed as multivariate sequence with discrete and continuous features and variable length. This characteristic alone creates problems explored in \autoref{sec:sequences}. \attention{Also refer to variability in sequence section.} However, the data is also just a \emph{sample} of the process. Hence, it may not reflect the real process in its entirety. In fact, mining techniques need to incorporate the \emph{open world assumption} as the original process may generate unseen \glspl{instance}.

A third issue which contributes to the datasets incompleteness and complexity is a phenomenon called \emph{concept drift}. This phenomenon relates possibility of a change in the \emph{true} process. The change may occur suddenly or gradually and can appear in isolation or periodically. An expression of such a drift may be a sudden inclusion of a new process step or domain changes of certain features. These changes are not uncommon and their likelihood increases with the temporal coverage and level of granularity of the dataset\needscite. In other words, the more \emph{time} the dataset covers and the higher its detail, the more likely a change might have occured over the time.

All three issues relate to the \emph{representativeness} of the data with regards to the unknown \emph{true} process that generated the data. However, they also represent open challenges that require research on their own. For our purpose, we have to assume that the data is representative and its underlying process is static. These assumptions are widely applied in the body of process mining literature\needscite.
\end{document}