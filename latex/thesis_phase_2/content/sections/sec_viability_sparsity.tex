\documentclass[./../../paper.tex]{subfiles}
\graphicspath{{\subfix{./../../figures/}}}

\begin{document}

Sparsity refers to the number of changes between the factual and counterfactual sequence. We typically want to minimize the number of changes. However, sparcity is hard to measure, as we cannot easily count the changes. There are two reasons, why this is the case: First, the sequences that are compared can have varying lengths. Second, even if they were the same length, the events might not line up in such a way, that we can simply count the changes to a feature. Hence, to solve this issue, we use the previously established \gls{SSDLD}. The sparcity distance uses a cost function as specified in \autoref{eq:sparcity_measure}.

\begin{align}
    \label{eq:sparcity_measure}                          
    \editCostFunctionBoth      & = \sum_d \mathbb{I}(a_{id} = b_{jd})  \\ 
    a_i,b_j        & \in \mathbb{R}^d \nonumber 
\end{align}

\noindent Here, $\sum_d \mathbb{I}(a_{id} = b_{jd})$ is an indicator function, that is used to count the number of changes in a vector. 





% \begin{figure}
%     \begin{tikzpicture}[>=stealth,thick,baseline]
        


%         \matrix [matrix of math nodes, left delimiter=(,right delimiter=)](m1){ 
%             a & b &  a   \\
%             0.6 & 0.25 &  0.64   \\  
%             0 & 0 &  1   \\
%             1.2 & 4.5 &  3.3   \\
%        };
        
%         \node[draw, blue!80, dashed, thin, inner sep=2mm,fit=(m1-1-1.west) (m1-1-3.east)] (actbox) {};
%         \node[draw,  red!80, dashed, thin, inner sep=2mm,fit=(m1-2-1.west) (m1-4-3.east)] (attbox) {};
        
%         % \node[draw, above = of m1-1-1](e1r) {$e_1$};
%         % \node[draw, right = of e1r](e2r) {$e_2$};
%         % \node[draw, right = of e2r](e3r) {$e_3$};

%         % \draw[->, right = of e1r](e1r) -- (e2r);
%         % \draw[->, right = of e2r](e2r) -- (e3r);
        
%         \node[above = of m1](rlbl) {Factual};


%         % \node[above = 0.5mm of me] {Events};
%         \node[above = 4mm of actbox, blue!80](lb1) {\tiny Activity};
%         \node[below = 4mm of attbox, red!80](lb2) {\tiny Features};
%         % \node[right = 1mm of bracket, purple!80] {\tiny Hybrid-Representation};
        
%         \matrix [matrix of math nodes,left delimiter=(,right delimiter=), right = 11em of m1](m2){ 
%             a & b &  a   & c & c & d\\
%             0.6 & 0.75 &  0.64   & 0.57 & 0.1 & 0.3\\  
%             0 & 0 &  1   & 0 & 1 & 0 \\
%             1.2 & 4.5 &  3.3   & 3.0 & 6.8 & 9.1  \\
%             };

%         % \node[draw, above = of m2-1-1](e1l) {$e_1$};
%         % \node[draw, above = of m2-1-2](e2l) {$e_2$};
%         % \node[draw, above = of m2-1-3](e3l) {$e_3$};
%         % \node[draw, above = of m2-1-4](e4l) {$e_4$};

%         % \draw[->, right = of e1l](e1l) -- (e2l);
%         % \draw[->, right = of e2l](e2l) -- (e3l);
%         % \draw[->, right = of e3l](e3l) -- (e4l);
        
%         \node[above = of m2](rlbl) {Counterfactual};
    
%         \node[draw, blue!80, dashed, thin, inner sep=2mm,fit=(m2-1-1.west) (m2-1-3.east)] (actbox-m2) {};
%         \node[draw,  red!80, dashed, thin, inner sep=2mm,fit=(m2-2-1.west) (m2-4-3.east)] (attbox-m2) {};
    
%         \node[above = 4mm of actbox-m2, blue!80](lb1) {\tiny Activity};
%         \node[below = 4mm of attbox-m2, red!80](lb2) {\tiny Features};

%         \end{tikzpicture}
%         \caption{Two sequences. A factual sequence and a counterfactual sequence.}
%         \label{fig:example-sparsity}
% \end{figure}

% To get a better intuition, let us consider an example: We consider two sequences as shown in \autoref{fig:example-sparsity}. In this example, a sequence of factual activities $aba$ and a sequence of counterfactual activities $abac$. $a$ and $b$ are two different activities. I we consider a loan application process, we could interpret these activities as $a$ being an approval and $b$ being a request for more information.   

% We see, also see their event attributes. These could be related to the applicants credit score, their yearly income or other case related information. Hence, one could say that the first events in both cases are identical. If our sparsity measure only counts the number of changes of the first event, we get a sparsity-cost of 0. However, this is a sequence and the next event does display a change. The first dimension of the second event on the factual side is 0.25, while it is 0.75 on the counterfactual. It is clear that the sparsity is worse on the second event. In fact, according to \autoref{eq:sparcity_measure} we now have a sparcity cost of 1. The third events in both sequences are identical again. Hence, no cost. However, it is difficult to argue that the cost of both sequences is just 1. Mainly because the counterfactual has a fourth event. This difference between the two sequences reveals the improtance of structural differences between sequences. Mainly, if we do not take the structure into account, we run the risk of misrepresenting the distance, we perceive.  




\end{document}